{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Time series forecasting\n",
        "\n",
        "## Score: .2618"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "os.environ['LOKY_MAX_CPU_COUNT'] = str(os.cpu_count() or 4)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Paths: Kaggle or local\n",
        "if os.path.exists('/kaggle/input/ts-forecasting/train.parquet'):\n",
        "    TRAIN_PATH = '/kaggle/input/ts-forecasting/train.parquet'\n",
        "    TEST_PATH = '/kaggle/input/ts-forecasting/test.parquet'\n",
        "else:\n",
        "    TRAIN_PATH = 'ts-forecasting/train.parquet'\n",
        "    TEST_PATH = 'ts-forecasting/test.parquet'\n",
        "\n",
        "VAL_THRESHOLD = 3500\n",
        "\n",
        "\n",
        "def weighted_rmse_score(y_target, y_pred, w):\n",
        "    \"\"\"Competition metric. Higher is better.\"\"\"\n",
        "    y_target, y_pred, w = np.array(y_target), np.array(y_pred), np.array(w)\n",
        "    denom = np.sum(w * (y_target ** 2))\n",
        "    if denom <= 0:\n",
        "        return 0.0\n",
        "    numerator = np.sum(w * ((y_target - y_pred) ** 2))\n",
        "    ratio = numerator / denom\n",
        "    return float(np.sqrt(1.0 - np.clip(ratio, 0.0, 1.0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train stats computed.\n"
          ]
        }
      ],
      "source": [
        "# Train stats from data with ts_index <= val_threshold (no look-forward)\n",
        "temp = pd.read_parquet(TRAIN_PATH, columns=['sub_category', 'sub_code', 'y_target', 'ts_index'])\n",
        "train_only = temp[temp['ts_index'] <= VAL_THRESHOLD]\n",
        "train_stats = {\n",
        "    'sub_category': train_only.groupby('sub_category')['y_target'].mean().to_dict(),\n",
        "    'sub_code': train_only.groupby('sub_code')['y_target'].mean().to_dict(),\n",
        "    'global_mean': train_only['y_target'].mean()\n",
        "}\n",
        "del temp, train_only\n",
        "gc.collect()\n",
        "print('Train stats computed.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_context_features(data, enc_stats=None):\n",
        "    \"\"\"Context-aware features: encoded categoricals, interactions, lags, temporal cycle.\"\"\"\n",
        "    x = data.copy()\n",
        "    group_cols = ['code', 'sub_code', 'sub_category', 'horizon']\n",
        "    x = x.sort_values(group_cols + ['ts_index'])\n",
        "\n",
        "    if enc_stats is not None:\n",
        "        for c in ['sub_category', 'sub_code']:\n",
        "            x[c + '_enc'] = x[c].map(enc_stats[c]).fillna(enc_stats['global_mean']).astype(np.float32)\n",
        "\n",
        "    # Interaction features\n",
        "    if 'feature_al' in x.columns and 'feature_am' in x.columns:\n",
        "        x['d_al_am'] = (x['feature_al'] - x['feature_am']).astype(np.float32)\n",
        "        x['r_al_am'] = (x['feature_al'] / (x['feature_am'] + 1e-7)).astype(np.float32)\n",
        "    if 'feature_cg' in x.columns and 'feature_by' in x.columns:\n",
        "        x['d_cg_by'] = (x['feature_cg'] - x['feature_by']).astype(np.float32)\n",
        "\n",
        "    top_features = ['feature_al', 'feature_am', 'feature_cg', 'feature_by', 'feature_s']\n",
        "    for col in top_features:\n",
        "        if col not in x.columns:\n",
        "            continue\n",
        "        for lag in [1, 3, 10]:\n",
        "            x[f'{col}_lag{lag}'] = x.groupby(group_cols)[col].shift(lag).astype(np.float32)\n",
        "        x[f'{col}_diff1'] = x.groupby(group_cols)[col].diff(1).astype(np.float32)\n",
        "        for window in [5, 10]:\n",
        "            x[f'{col}_roll{window}'] = x.groupby(group_cols)[col].transform(\n",
        "                lambda s: s.rolling(window, min_periods=1).mean()\n",
        "            ).astype(np.float32)\n",
        "            x[f'{col}_rollstd{window}'] = x.groupby(group_cols)[col].transform(\n",
        "                lambda s: s.rolling(window, min_periods=1).std()\n",
        "            ).astype(np.float32)\n",
        "        x[f'{col}_ewm5'] = x.groupby(group_cols)[col].transform(\n",
        "            lambda s: s.ewm(span=5, adjust=False).mean()\n",
        "        ).astype(np.float32)\n",
        "\n",
        "    x['t_cycle'] = np.sin(2 * np.pi * x['ts_index'].astype(np.float32) / 100).astype(np.float32)\n",
        "    return x\n",
        "\n",
        "\n",
        "LGB_CFG = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse',\n",
        "    'learning_rate': 0.015,\n",
        "    'n_estimators': 4000,\n",
        "    'num_leaves': 80,\n",
        "    'min_child_samples': 200,\n",
        "    'feature_fraction': 0.6,\n",
        "    'bagging_fraction': 0.7,\n",
        "    'bagging_freq': 5,\n",
        "    'lambda_l1': 0.1,\n",
        "    'lambda_l2': 10.0,\n",
        "    'verbosity': -1,\n",
        "}\n",
        "SEEDS = (42, 2024, 7, 11, 999)\n",
        "N_SEEDS = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> Training horizon = 1\n",
            "Horizon 1 Score: 0.06690\n",
            "\n",
            ">>> Training horizon = 3\n",
            "Horizon 3 Score: 0.12382\n",
            "\n",
            ">>> Training horizon = 10\n",
            "Horizon 10 Score: 0.21332\n",
            "\n",
            ">>> Training horizon = 25\n",
            "Horizon 25 Score: 0.25960\n"
          ]
        }
      ],
      "source": [
        "forecast_windows = [1, 3, 10, 25]\n",
        "test_outputs = []\n",
        "cv_cache = {'y': [], 'pred': [], 'wt': []}\n",
        "\n",
        "for hz in forecast_windows:\n",
        "    print(f'\\n>>> Training horizon = {hz}')\n",
        "    tr_df = build_context_features(\n",
        "        pd.read_parquet(TRAIN_PATH).query(f'horizon == {hz}'),\n",
        "        train_stats\n",
        "    )\n",
        "    te_df = build_context_features(\n",
        "        pd.read_parquet(TEST_PATH).query(f'horizon == {hz}'),\n",
        "        train_stats\n",
        "    )\n",
        "\n",
        "    feature_cols = [\n",
        "        c for c in tr_df.columns\n",
        "        if c not in {'id', 'code', 'sub_code', 'sub_category', 'horizon', 'ts_index', 'weight', 'y_target'}\n",
        "    ]\n",
        "    for c in feature_cols:\n",
        "        tr_df[c] = tr_df[c].fillna(0).astype(np.float32)\n",
        "        te_df[c] = te_df[c].fillna(0).astype(np.float32)\n",
        "\n",
        "    fit_mask = tr_df['ts_index'] <= VAL_THRESHOLD\n",
        "    val_mask = ~fit_mask\n",
        "\n",
        "    X_fit = tr_df.loc[fit_mask, feature_cols]\n",
        "    y_fit = tr_df.loc[fit_mask, 'y_target']\n",
        "    w_fit = tr_df.loc[fit_mask, 'weight']\n",
        "\n",
        "    X_hold = tr_df.loc[val_mask, feature_cols]\n",
        "    y_hold = tr_df.loc[val_mask, 'y_target']\n",
        "    w_hold = tr_df.loc[val_mask, 'weight']\n",
        "\n",
        "    val_pred = np.zeros(len(y_hold), dtype=np.float64)\n",
        "    tst_pred = np.zeros(len(te_df), dtype=np.float64)\n",
        "\n",
        "    for seed in SEEDS:\n",
        "        mdl = lgb.LGBMRegressor(**LGB_CFG, random_state=seed, n_jobs=-1)\n",
        "        mdl.fit(\n",
        "            X_fit, y_fit,\n",
        "            sample_weight=w_fit,\n",
        "            eval_set=[(X_hold, y_hold)],\n",
        "            eval_sample_weight=[w_hold],\n",
        "            callbacks=[lgb.early_stopping(200, verbose=False)]\n",
        "        )\n",
        "        val_pred += mdl.predict(X_hold).astype(np.float64) / N_SEEDS\n",
        "        tst_pred += mdl.predict(te_df[feature_cols]).astype(np.float64) / N_SEEDS\n",
        "        del mdl\n",
        "        gc.collect()\n",
        "\n",
        "    print(f'Horizon {hz} Score: {weighted_rmse_score(y_hold, val_pred, w_hold):.5f}')\n",
        "\n",
        "    cv_cache['y'].extend(y_hold.tolist())\n",
        "    cv_cache['pred'].extend(val_pred.tolist())\n",
        "    cv_cache['wt'].extend(w_hold.tolist())\n",
        "\n",
        "    test_outputs.append(pd.DataFrame({'id': te_df['id'].values, 'prediction': tst_pred}))\n",
        "\n",
        "    del tr_df, te_df, X_fit, y_fit, w_fit, X_hold, y_hold, w_hold\n",
        "    gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "========================================\n",
            "FINAL AGGREGATE SCORE: 0.223828\n",
            "========================================\n",
            "Submission shape: (1447107, 2)\n",
            "First 10 rows (must match test row order):\n",
            "                                       id  prediction\n",
            "0   W2MW3G2L__495MGHFJ__PZ9S1Z4V__3__3647   -0.053746\n",
            "1  W2MW3G2L__495MGHFJ__PZ9S1Z4V__10__3647   -0.103430\n",
            "2  W2MW3G2L__495MGHFJ__PZ9S1Z4V__25__3647   -0.362948\n",
            "3   W2MW3G2L__495MGHFJ__PZ9S1Z4V__1__3647   -0.008905\n",
            "4  W2MW3G2L__495MGHFJ__PZ9S1Z4V__10__3648   -0.112227\n",
            "5  W2MW3G2L__495MGHFJ__PZ9S1Z4V__25__3648   -0.454240\n",
            "6   W2MW3G2L__495MGHFJ__PZ9S1Z4V__3__3648   -0.044495\n",
            "7   W2MW3G2L__495MGHFJ__PZ9S1Z4V__1__3648   -0.011438\n",
            "8   W2MW3G2L__495MGHFJ__PZ9S1Z4V__3__3649   -0.044476\n",
            "9  W2MW3G2L__495MGHFJ__PZ9S1Z4V__25__3649   -0.434736\n"
          ]
        }
      ],
      "source": [
        "final_metric = weighted_rmse_score(cv_cache['y'], cv_cache['pred'], cv_cache['wt'])\n",
        "print(f\"\\n{'='*40}\\nFINAL AGGREGATE SCORE: {final_metric:.6f}\\n{'='*40}\")\n",
        "\n",
        "# Submission: MUST be in exact test.parquet row order (row i = test row i)\n",
        "test_full = pd.read_parquet(TEST_PATH)\n",
        "pred_dict = {}\n",
        "for df in test_outputs:\n",
        "    for i in range(len(df)):\n",
        "        k = str(df['id'].iloc[i]).strip()\n",
        "        pred_dict[k] = float(df['prediction'].iloc[i])\n",
        "\n",
        "# Normalize test ids the same way for lookup\n",
        "test_ids = test_full['id'].astype(str).str.strip()\n",
        "missing = test_ids[~test_ids.isin(pred_dict)].unique()\n",
        "if len(missing) > 0:\n",
        "    raise RuntimeError(f\"{len(missing)} test ids not in pred_dict (e.g. {list(missing[:3])})\")\n",
        "if len(pred_dict) != len(test_full):\n",
        "    raise RuntimeError(f\"pred_dict has {len(pred_dict)} keys but test has {len(test_full)} rows\")\n",
        "\n",
        "# Build submission in test row order and write row-by-row (no reorder)\n",
        "with open('submission.csv', 'w', newline='') as f:\n",
        "    f.write('id,prediction\\n')\n",
        "    for i in range(len(test_full)):\n",
        "        id_val = test_full['id'].iloc[i]\n",
        "        key = str(id_val).strip()\n",
        "        pred = pred_dict[key]\n",
        "        if np.isnan(pred):\n",
        "            raise RuntimeError(f\"NaN prediction for id {id_val}\")\n",
        "        f.write(f\"{id_val},{pred:.10f}\\n\")\n",
        "\n",
        "submission = pd.read_csv('submission.csv')\n",
        "print(f'Submission shape: {submission.shape}')\n",
        "print('First 10 rows (must match test row order):')\n",
        "print(submission.head(10))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
