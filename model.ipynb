{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series forecasting\n",
    "\n",
    "## Score: .2154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "os.environ['LOKY_MAX_CPU_COUNT'] = str(os.cpu_count() or 4)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'ts-forecasting/train.parquet'\n",
    "TEST_PATH = 'ts-forecasting/test.parquet'\n",
    "VAL_THRESHOLD = 3500\n",
    "\n",
    "\n",
    "def reduce_mem_usage(df):\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if col_type != object:\n",
    "            c_min, c_max = df[col].min(), df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "            else:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "    return df\n",
    "\n",
    "\n",
    "def weighted_rmse_score(y_target, y_pred, w):\n",
    "    y_target = np.array(y_target, dtype=np.float64)\n",
    "    y_pred = np.array(y_pred, dtype=np.float64)\n",
    "    w = np.array(w, dtype=np.float64)\n",
    "    denom = np.sum(w * y_target ** 2)\n",
    "    if denom == 0 or np.isnan(denom):\n",
    "        return 0.0\n",
    "    ratio = np.sum(w * (y_target - y_pred) ** 2) / denom\n",
    "    clipped = np.clip(ratio, 0.0, 1.0)\n",
    "    return float(np.sqrt(1.0 - clipped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train (minimal columns)...\n",
      "Train shape: (5337414, 7)\n",
      "Encodings computed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "771"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Loading train (minimal columns)...')\n",
    "train_cols = ['code', 'sub_code', 'sub_category', 'horizon', 'ts_index', 'y_target', 'weight']\n",
    "train_df = pd.read_parquet(TRAIN_PATH, columns=train_cols)\n",
    "print(f'Train shape: {train_df.shape}')\n",
    "\n",
    "global_encodings = {}\n",
    "for col in ['code', 'sub_code', 'sub_category']:\n",
    "    freq_map = train_df[col].value_counts(normalize=True).to_dict()\n",
    "    global_encodings[f'{col}_freq'] = freq_map\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_df[col].astype(str))\n",
    "    global_encodings[f'{col}_le'] = le\n",
    "    global_mean = train_df['y_target'].mean()\n",
    "    counts = train_df[col].value_counts()\n",
    "    target_sum = train_df.groupby(col)['y_target'].sum()\n",
    "    alpha = 10\n",
    "    target_mean = {}\n",
    "    for cat in counts.index:\n",
    "        n = counts[cat]\n",
    "        sum_val = target_sum.get(cat, 0)\n",
    "        target_mean[cat] = (sum_val + alpha * global_mean) / (n + alpha)\n",
    "    global_encodings[f'{col}_target_mean'] = target_mean\n",
    "    global_encodings[f'{col}_global_mean'] = global_mean\n",
    "\n",
    "print('Encodings computed.')\n",
    "del train_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_minimal(df, global_encodings):\n",
    "    df = df.copy()\n",
    "    group_cols = ['code', 'sub_code', 'sub_category', 'horizon']\n",
    "    for col in ['code', 'sub_code', 'sub_category']:\n",
    "        df[f'{col}_freq'] = df[col].map(global_encodings[f'{col}_freq']).fillna(0.0).astype(np.float32)\n",
    "        le = global_encodings[f'{col}_le']\n",
    "        col_values = df[col].astype(str)\n",
    "        encoded = np.full(len(col_values), -1, dtype=np.int16)\n",
    "        for i, val in enumerate(col_values):\n",
    "            if val in le.classes_:\n",
    "                encoded[i] = le.transform([val])[0]\n",
    "        df[f'{col}_encoded'] = encoded\n",
    "        gm = global_encodings[f'{col}_global_mean']\n",
    "        df[f'{col}_target_mean'] = df[col].map(global_encodings[f'{col}_target_mean']).fillna(gm).astype(np.float32)\n",
    "    df['horizon_numeric'] = df['horizon'].astype(np.int8)\n",
    "    df = df.sort_values(group_cols + ['ts_index'])\n",
    "    df['position'] = df.groupby(group_cols).cumcount().astype(np.int16)\n",
    "    df['ts_mod_7'] = (df['ts_index'] % 7).astype(np.int8)\n",
    "    top_features = ['feature_al', 'feature_am', 'feature_cg', 'feature_by', 'feature_s']\n",
    "    for col in top_features:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        for lag in [1, 3, 10]:\n",
    "            df[f'{col}_lag{lag}'] = df.groupby(group_cols)[col].shift(lag).astype(np.float32)\n",
    "        df[f'{col}_diff1'] = df.groupby(group_cols)[col].diff(1).astype(np.float32)\n",
    "        for window in [5, 10]:\n",
    "            df[f'{col}_roll{window}'] = df.groupby(group_cols)[col].transform(\n",
    "                lambda x: x.rolling(window, min_periods=1).mean()\n",
    "            ).astype(np.float32)\n",
    "            df[f'{col}_rollstd{window}'] = df.groupby(group_cols)[col].transform(\n",
    "                lambda x: x.rolling(window, min_periods=1).std()\n",
    "            ).astype(np.float32)\n",
    "        df[f'{col}_ewm5'] = df.groupby(group_cols)[col].transform(\n",
    "            lambda x: x.ewm(span=5, adjust=False).mean()\n",
    "        ).astype(np.float32)\n",
    "    if 'feature_al' in df.columns and 'feature_am' in df.columns:\n",
    "        df['al_x_am'] = (df['feature_al'] * df['feature_am']).astype(np.float32)\n",
    "    if 'feature_by' in df.columns and 'feature_s' in df.columns:\n",
    "        df['by_x_s'] = (df['feature_by'] * df['feature_s']).astype(np.float32)\n",
    "    for c in df.columns:\n",
    "        if c.startswith('feature_') and df[c].dtype != np.float32:\n",
    "            df[c] = df[c].astype(np.float32)\n",
    "    return df\n",
    "\n",
    "\n",
    "horizon_params = {\n",
    "    1: {'n_estimators': 3000, 'learning_rate': 0.015, 'max_depth': 9, 'num_leaves': 200, 'min_child_samples': 5},\n",
    "    3: {'n_estimators': 3000, 'learning_rate': 0.015, 'max_depth': 9, 'num_leaves': 200, 'min_child_samples': 5},\n",
    "    10: {'n_estimators': 2500, 'learning_rate': 0.02, 'max_depth': 9, 'num_leaves': 150, 'min_child_samples': 5},\n",
    "    25: {'n_estimators': 2000, 'learning_rate': 0.025, 'max_depth': 9, 'num_leaves': 120, 'min_child_samples': 5}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horizon 1...\n",
      "  Val score: 0.045735\n",
      "Horizon 3...\n",
      "  Val score: 0.099050\n",
      "Horizon 10...\n",
      "  Val score: 0.173886\n",
      "Horizon 25...\n",
      "  Val score: 0.242699\n"
     ]
    }
   ],
   "source": [
    "all_val_results = []\n",
    "all_test_predictions = []\n",
    "\n",
    "for horizon in [1, 3, 10, 25]:\n",
    "    print(f'Horizon {horizon}...')\n",
    "    train_h = pd.read_parquet(TRAIN_PATH)\n",
    "    train_h = train_h[train_h['horizon'] == horizon].copy()\n",
    "    train_h = reduce_mem_usage(train_h)\n",
    "    test_h = pd.read_parquet(TEST_PATH)\n",
    "    test_h = test_h[test_h['horizon'] == horizon].copy()\n",
    "    test_h = reduce_mem_usage(test_h)\n",
    "\n",
    "    train_h = create_features_minimal(train_h, global_encodings)\n",
    "    test_h = create_features_minimal(test_h, global_encodings)\n",
    "    exclude = ['id', 'code', 'sub_code', 'sub_category', 'horizon', 'ts_index', 'weight', 'y_target']\n",
    "    feature_cols = [c for c in train_h.columns if c not in exclude]\n",
    "\n",
    "    for c in feature_cols:\n",
    "        train_h[c] = train_h[c].fillna(0).astype(np.float32)\n",
    "        test_h[c] = test_h[c].fillna(0).astype(np.float32)\n",
    "\n",
    "    train_mask = train_h['ts_index'] <= VAL_THRESHOLD\n",
    "    X_train = train_h.loc[train_mask, feature_cols].values.astype(np.float32)\n",
    "    y_train = train_h.loc[train_mask, 'y_target'].values.astype(np.float32)\n",
    "    w_train = train_h.loc[train_mask, 'weight'].values.astype(np.float64)\n",
    "    X_val = train_h.loc[~train_mask, feature_cols].values.astype(np.float32)\n",
    "    y_val = train_h.loc[~train_mask, 'y_target'].values.astype(np.float32)\n",
    "    w_val = train_h.loc[~train_mask, 'weight'].values.astype(np.float64)\n",
    "    X_test = test_h[feature_cols].values.astype(np.float32)\n",
    "    test_ids = test_h['id'].values\n",
    "\n",
    "    params = horizon_params[horizon]\n",
    "    val_preds_list = []\n",
    "    test_preds_list = []\n",
    "    for seed in [42, 420, 80085]:\n",
    "        model = lgb.LGBMRegressor(\n",
    "            n_estimators=params['n_estimators'], learning_rate=params['learning_rate'],\n",
    "            max_depth=params['max_depth'], num_leaves=params['num_leaves'],\n",
    "            min_child_samples=params['min_child_samples'], subsample=0.85, colsample_bytree=0.85,\n",
    "            reg_alpha=0.1, reg_lambda=0.1, random_state=seed, verbose=-1, n_jobs=-1\n",
    "        )\n",
    "        model.fit(X_train, y_train, sample_weight=w_train,\n",
    "                  eval_set=[(X_val, y_val)], eval_sample_weight=[w_val],\n",
    "                  callbacks=[lgb.early_stopping(300, verbose=False)])\n",
    "        val_preds_list.append(model.predict(X_val))\n",
    "        test_preds_list.append(model.predict(X_test))\n",
    "        del model\n",
    "        gc.collect()\n",
    "\n",
    "    val_pred_avg = np.mean(val_preds_list, axis=0)\n",
    "    test_pred_avg = np.mean(test_preds_list, axis=0)\n",
    "    h_score = weighted_rmse_score(y_val, val_pred_avg, w_val)\n",
    "    print(f'  Val score: {h_score:.6f}')\n",
    "    all_val_results.append({'horizon': horizon, 'score': h_score, 'y_val': y_val, 'pred_val': val_pred_avg, 'w_val': w_val})\n",
    "    all_test_predictions.append({'ids': test_ids, 'preds': test_pred_avg})\n",
    "    del train_h, test_h, X_train, y_train, w_train, X_val, y_val, w_val, X_test\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation score: 0.200962\n",
      "  H1: 0.045735\n",
      "  H3: 0.099050\n",
      "  H10: 0.173886\n",
      "  H25: 0.242699\n",
      "Submission shape: (1447107, 2)\n",
      "                                       id  prediction\n",
      "0   W2MW3G2L__495MGHFJ__PZ9S1Z4V__3__3647   -0.005317\n",
      "1  W2MW3G2L__495MGHFJ__PZ9S1Z4V__10__3647   -0.039086\n",
      "2  W2MW3G2L__495MGHFJ__PZ9S1Z4V__25__3647   -0.273217\n",
      "3   W2MW3G2L__495MGHFJ__PZ9S1Z4V__1__3647   -0.007185\n",
      "4  W2MW3G2L__495MGHFJ__PZ9S1Z4V__10__3648   -0.073280\n",
      "5  W2MW3G2L__495MGHFJ__PZ9S1Z4V__25__3648   -0.261707\n",
      "6   W2MW3G2L__495MGHFJ__PZ9S1Z4V__3__3648   -0.007679\n",
      "7   W2MW3G2L__495MGHFJ__PZ9S1Z4V__1__3648   -0.007010\n",
      "8   W2MW3G2L__495MGHFJ__PZ9S1Z4V__3__3649   -0.018594\n",
      "9  W2MW3G2L__495MGHFJ__PZ9S1Z4V__25__3649   -0.248694\n"
     ]
    }
   ],
   "source": [
    "all_y_val = np.concatenate([r['y_val'] for r in all_val_results])\n",
    "all_pred_val = np.concatenate([r['pred_val'] for r in all_val_results])\n",
    "all_w_val = np.concatenate([r['w_val'] for r in all_val_results])\n",
    "overall_score = weighted_rmse_score(all_y_val, all_pred_val, all_w_val)\n",
    "print(f'Overall validation score: {overall_score:.6f}')\n",
    "for r in all_val_results:\n",
    "    print(f\"  H{r['horizon']}: {r['score']:.6f}\")\n",
    "\n",
    "all_ids = np.concatenate([p['ids'] for p in all_test_predictions])\n",
    "all_preds = np.concatenate([p['preds'] for p in all_test_predictions])\n",
    "submission = pd.DataFrame({'id': all_ids, 'prediction': all_preds})\n",
    "test_full = pd.read_parquet(TEST_PATH)\n",
    "submission = submission.set_index('id').reindex(test_full['id']).reset_index()\n",
    "submission['prediction'] = submission['prediction'].fillna(all_preds.mean())\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f'Submission shape: {submission.shape}')\n",
    "print(submission.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
